# Terraform Best Practices Analyzer

ğŸ” **AI-powered Terraform module analyzer** that identifies missing best practices and provides actionable recommendations for improving security, performance, compliance, and cost optimization.

## âœ¨ Overview

This tool uses a **multi-agent architecture** with Strands Agents to analyze your existing Terraform code and suggest improvements based on official Terraform Registry documentation and AWS best practices.

### How It Works

```
Your Terraform Code â†’ 4-Step Analysis â†’ Detailed Recommendations
```

#### 4-Step Multi-Agent Workflow

1. **ğŸ“– Read Terraform Code** - Scans all `.tf` files in your module
2. **ğŸ” Identify AWS Services** - Ollama agent analyzes code to detect all AWS services
3. **ğŸ”§ Fetch Best Practices** - MCP agent queries Terraform Registry for official documentation
4. **ğŸ’¡ Generate Recommendations** - Ollama agent compares your code with best practices and provides specific, actionable suggestions

## ğŸš€ Quick Start

### Prerequisites

```bash
# 1. Install Python dependencies
pip install -r requirements.txt

# Or install manually:
# pip install 'strands-agents[ollama]' strands-agents-tools mcp

# 2. Pull Docker image for Terraform MCP Server
docker pull hashicorp/terraform-mcp-server

# 3. Install Ollama model (7B+ recommended)
ollama pull llama3.2
```

### Usage

```bash
python main.py <terraform_module_directory>
```

**Example:**
```bash
python main.py ./s3
```

The analysis output is automatically saved to a file with format:
```
terraform_analysis_<module_name>_<unix_timestamp>.txt
```

For example:
```
terraform_analysis_s3_1702218345.txt
```

## ğŸ“Š What You Get

The tool generates a comprehensive analysis report with:

### âœ… Current Implementation Summary
- List of all AWS services currently configured
- Inventory of Terraform resources in use

### âŒ Missing Best Practices
Categorized by:
- **Security**: Missing encryption, access controls, logging
- **Performance**: Missing monitoring, optimization features
- **Compliance**: Missing versioning, backup, audit trails
- **Cost Optimization**: Missing lifecycle policies, intelligent tiering

### ğŸ’¡ Actionable Recommendations
For each recommendation:
- **What to add**: Specific Terraform resource(s) needed
- **Why it matters**: Security/performance/compliance benefit
- **How to implement**: Code example showing the configuration
- **Priority level**: HIGH / MEDIUM / LOW

## ğŸ¯ Example Output

```bash
$ python main.py ./s3

================================================================================
ğŸ” TERRAFORM BEST PRACTICES ANALYZER
================================================================================

ğŸ“‚ Analyzing module: ./s3

================================================================================
ğŸ“– STEP 1: Reading Terraform code...
================================================================================

ğŸ“‚ Module Directory: ./s3
ğŸ“„ Found 1 Terraform file(s) (28 lines total):
   - s3.tf

================================================================================
ğŸ” STEP 2: Identifying AWS services in the code...
================================================================================

âœ… AWS Services identified in code:
["s3", "kms"]

================================================================================
ğŸ”§ STEP 3: Fetching best practices from Terraform Registry...
================================================================================

âœ… Using 34 MCP tools from Terraform Registry
â³ Fetching comprehensive resource documentation...

âœ… Best practices documentation retrieved from Registry

================================================================================
ğŸ’¡ STEP 4: Analyzing code and generating recommendations...
================================================================================

================================================================================
âœ¨ BEST PRACTICES RECOMMENDATIONS
================================================================================

## Current Implementation Summary

Your S3 module currently implements:
- aws_s3_bucket (main bucket resource)
- aws_s3_bucket_versioning (enabled)
- aws_s3_bucket_public_access_block (configured)

## Missing Best Practices

### ğŸ” Security (HIGH Priority)

**1. Server-Side Encryption**
- Missing: aws_s3_bucket_server_side_encryption_configuration
- Why: Encrypts data at rest, protecting against unauthorized access
- How to implement:

resource "aws_s3_bucket_server_side_encryption_configuration" "bucket_encryption" {
  bucket = aws_s3_bucket.my_bucket.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.mykey.arn
    }
  }
}

**2. Bucket Logging**
- Missing: aws_s3_bucket_logging
- Why: Audit trail for compliance and security monitoring
- Priority: HIGH

### âš¡ Performance (MEDIUM Priority)

**3. CloudWatch Metrics**
- Missing: aws_s3_bucket_metric
- Why: Monitor bucket performance and usage patterns
...

ğŸ‰ ANALYSIS COMPLETED SUCCESSFULLY!
```

## ğŸ—ï¸ Architecture

### Multi-Agent System

The tool uses a **modular multi-agent architecture** with specialized agents coordinated by an orchestrator:

```
main.py (Orchestrator)
    â†“
    â”œâ”€â†’ agents/service_analyzer_agent.py (Agent 1)
    â”‚   â””â”€â†’ Identifies AWS services in code
    â”‚
    â”œâ”€â†’ agents/resources_fetcher_agent.py (Agent 2)
    â”‚   â””â”€â†’ Queries Terraform Registry via MCP
    â”‚
    â””â”€â†’ agents/best_practices_advisor_agent.py (Agent 3)
        â””â”€â†’ Generates actionable recommendations
```

### Agent Details

| Agent | File | Model | Purpose | Tools |
|-------|------|-------|---------|-------|
| **Service Analyzer** | `service_analyzer_agent.py` | Ollama (llama3.2) | Identifies AWS services in Terraform code | - |
| **Resources Fetcher** | `resources_fetcher_agent.py` | Anthropic (default) | Queries Terraform Registry for best practices | 34 MCP tools |
| **Best Practices Advisor** | `best_practices_advisor_agent.py` | Ollama (llama3.2) | Compares code with best practices and generates recommendations | - |

### Why This Design?

- **Modular architecture**: Each agent is a separate file with clear responsibilities
- **Ollama agents**: Fast, local processing for code analysis and recommendations
- **MCP agent**: Direct access to official Terraform Registry documentation
- **Separation of concerns**: Easy to maintain, test, and extend individual agents
- **Reusable components**: Agents can be imported and used independently

## ğŸ“‹ Requirements

### Essential
- âœ… **Python 3.10+** with required packages
- âœ… **Docker** running (for MCP server)
- âœ… **Ollama** with 7B+ model

### Recommended Models

| Model | Size | Analysis Quality | Speed | Recommendation |
|-------|------|------------------|-------|----------------|
| llama3.2 | 7B | âœ… Good | ğŸš€ Fast | âœ… **Recommended** |
| llama3.1:8b | 8B | âœ… Good | ğŸš€ Fast | âœ… **Recommended** |
| qwen2.5:7b | 7B | âœ… Good | ğŸš€ Fast | âœ… Good alternative |
| mixtral:8x7b | 47B | âœ… Excellent | ğŸ¢ Slow | âš¡ Best quality |

âš ï¸ **Note**: 3B models are NOT recommended - they struggle with complex analysis.

## ğŸ”§ Configuration

### Using Different Models

The tool uses Ollama for analysis agents. To change the model, edit the agent files:

**For Service Analyzer:**
```python
# In agents/service_analyzer_agent.py, line 4-10
ollama_model = OllamaModel(
    host="http://localhost:11434",
    model_id="llama3.2",  # Change this
    max_tokens=20000,
    temperature=0.1,
    keep_alive="10m",
)
```

**For Best Practices Advisor:**
```python
# In agents/best_practices_advisor_agent.py, line 4-10
ollama_model = OllamaModel(
    host="http://localhost:11434",
    model_id="llama3.2",  # Change this
    max_tokens=20000,
    temperature=0.1,
    keep_alive="10m",
)
```

### Using Default Anthropic Model

To use Anthropic's Claude instead of Ollama for analysis:

```python
# In agents/service_analyzer_agent.py or agents/best_practices_advisor_agent.py
# Comment out the model parameter in the Agent creation:
agent = Agent(
    # model=ollama_model,  # Comment this line
    system_prompt=SYSTEM_PROMPT,
)
```

### Extending the System

Thanks to the modular architecture, you can easily:

**Add new agents:**
```python
# Create agents/new_custom_agent.py
from strands import Agent, tool

@tool
def new_analysis_function(data: str) -> str:
    agent = Agent(system_prompt="...")
    return agent(data)
```

**Customize existing agents:**
Each agent file is self-contained and can be modified independently without affecting others.

## ğŸ“ Project Structure

### Tool Structure

```
terraform-suggestions/
â”œâ”€â”€ main.py                              # Orchestrator that coordinates all agents
â”œâ”€â”€ agents/                              # Multi-agent system
â”‚   â”œâ”€â”€ __init__.py                     # Package initialization
â”‚   â”œâ”€â”€ service_analyzer_agent.py       # Agent 1: Identifies AWS services
â”‚   â”œâ”€â”€ resources_fetcher_agent.py      # Agent 2: Queries Terraform Registry
â”‚   â””â”€â”€ best_practices_advisor_agent.py # Agent 3: Generates recommendations
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ README.md                            # Documentation
â””â”€â”€ example_output.txt                   # Sample analysis output
```

### Example Terraform Module Structure

```
my-terraform-project/
â”œâ”€â”€ s3/
â”‚   â”œâ”€â”€ s3.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â””â”€â”€ outputs.tf
â”œâ”€â”€ vpc/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ subnets.tf
â”‚   â””â”€â”€ security-groups.tf
â””â”€â”€ ec2/
    â”œâ”€â”€ instances.tf
    â””â”€â”€ iam.tf
```

Analyze each module:
```bash
python main.py ./s3
python main.py ./vpc
python main.py ./ec2
```

## ğŸ“ Use Cases

### Security Audit
```bash
python main.py ./production-infrastructure
```
Identifies missing encryption, access controls, logging, and security groups.

### Compliance Check
```bash
python main.py ./regulated-workload
```
Checks for versioning, backup, audit trails, and compliance-required features.

### Cost Optimization
```bash
python main.py ./data-storage
```
Suggests lifecycle policies, intelligent tiering, and storage optimization.

### Performance Review
```bash
python main.py ./high-traffic-app
```
Recommends monitoring, metrics, acceleration, and optimization features.

## ğŸ“„ Output Files

The tool automatically saves the complete analysis to a timestamped file for future reference:

**File naming format:**
```
terraform_analysis_<module_name>_<unix_timestamp>.txt
```

**Benefits:**
- ğŸ“ Keep historical records of your module's evolution
- ğŸ”„ Compare analyses over time as you implement recommendations
- ğŸ“¤ Share reports with your team easily
- ğŸ“Š Track improvements between analysis runs

**Example files:**
```
terraform_analysis_s3_1702218345.txt
terraform_analysis_vpc_1702218567.txt
terraform_analysis_ec2_1702218789.txt
```

**Tips:**
- Files are saved in the same directory where you run the command
- Compare different timestamps to see your progress
- Add these files to `.gitignore` (already configured)

## ğŸ› Troubleshooting

### "No Terraform files found"
**Cause:** Directory doesn't contain `.tf` files

**Solution:** 
- Verify the directory path is correct
- Ensure files have `.tf` extension
- Check you're not in a subdirectory

### Analysis gets stuck at Step 3
**Cause:** MCP server connection issue

**Solution:**
```bash
# Check Docker is running
docker ps

# Pull the image again
docker pull hashicorp/terraform-mcp-server

# Restart Docker if needed
```

### Agent returns generic advice instead of specific recommendations
**Cause:** Model too small or wrong model type

**Solution:**
- Use 7B+ model: `ollama pull llama3.2`
- Check Ollama is running: `ollama list`
- Verify model in code matches installed model

### Slow performance
**Causes:** Large model, complex module, or first run

**Solutions:**
- Keep Docker running to avoid startup time
- Use faster 7B model instead of 47B
- Increase `keep_alive` to 30m for multiple runs
- Simplify the module into smaller components

## ğŸ’¡ Best Practices for Using This Tool

1. **Start small**: Analyze one module at a time
2. **Prioritize**: Focus on HIGH priority recommendations first
3. **Iterate**: Apply changes, then re-analyze to verify
4. **Document**: Keep track of which recommendations you've implemented
5. **Learn**: Use the tool as a learning resource for Terraform best practices

## ğŸ” What Gets Analyzed

The tool examines all `.tf` files for:
- âœ… Resource definitions and configurations
- âœ… Data sources
- âœ… Variables and outputs
- âœ… Provider settings
- âœ… Module calls
- âœ… Terraform settings

It then compares against best practices for:
- ğŸ” **Security**: Encryption, access control, network security
- âš¡ **Performance**: Monitoring, caching, optimization
- ğŸ“‹ **Compliance**: Versioning, logging, audit trails
- ğŸ’° **Cost**: Lifecycle policies, tiering, resource optimization

## ğŸ“š Additional Resources

- [Strands Agents Documentation](https://strandsagents.com)
- [Terraform Registry](https://registry.terraform.io)
- [AWS Best Practices](https://aws.amazon.com/architecture/well-architected/)
- [Terraform MCP Server](https://github.com/hashicorp/terraform-mcp-server)
- [Ollama Models](https://ollama.com/library)
- [Model Context Protocol](https://modelcontextprotocol.io)

## ğŸ¤ Contributing

This tool is designed to be extensible. You can:
- Add support for other cloud providers (Azure, GCP)
- Customize the system prompts for different focus areas
- Add new analysis agents for specific compliance frameworks
- Integrate with CI/CD pipelines

## ğŸ“„ License

This project is open source and available under standard licensing terms.

---

**Built with:**
- [Strands Agents](https://strandsagents.com) - Multi-agent orchestration framework
- [Ollama](https://ollama.com) - Local LLM inference
- [Terraform MCP Server](https://github.com/hashicorp/terraform-mcp-server) - Access to Terraform Registry
- [Model Context Protocol](https://modelcontextprotocol.io) - Standardized AI-tool communication
